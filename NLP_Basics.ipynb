{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Basics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dFCxVGQXKBB"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnNZBZl0XOBx",
        "outputId": "6b8d5ff9-2c6c-46a1-9ff8-a7e19633fe0f"
      },
      "source": [
        "# Install the nltk component for several tasks\n",
        "nltk.download('punkt')     \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRrbBF4MXQJJ"
      },
      "source": [
        "sentence= \"The quick brown fox jumps over the lazy dog\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2x32qpXgtz"
      },
      "source": [
        "#**Tokenize**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cSyZCYeXQGo",
        "outputId": "a163df68-1565-4fd6-b27d-1a7fb5cf275e"
      },
      "source": [
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "print (tokens)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cUOU0m7Xt0V"
      },
      "source": [
        "# **POS Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3wpX6xUXQEH",
        "outputId": "48524ea0-296f-4f8b-91e5-1a7b1c58f79a"
      },
      "source": [
        "nltk.pos_tag(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('quick', 'JJ'),\n",
              " ('brown', 'NN'),\n",
              " ('fox', 'NN'),\n",
              " ('jumps', 'VBZ'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxwz6mtBZZyH"
      },
      "source": [
        "# **Stop Words Removal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN1b9NtCXP_t",
        "outputId": "b394d886-0b78-445e-c91d-b9d4d9039006"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print (stop_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'under', 'does', 'itself', 's', 'his', 'but', 'ourselves', 'through', 'to', \"should've\", \"wasn't\", 'y', 'were', 'then', 'haven', 'why', 'hadn', \"aren't\", 'is', 'our', 'll', 'ain', 'few', 'some', 'mightn', 'which', 're', 'for', 'nor', 'those', 'can', 'the', 'against', 'ma', 'aren', 'between', 'not', 'them', 'are', \"weren't\", 'has', 'she', 'into', 'on', 'up', \"mightn't\", 'am', 'should', \"you're\", 'same', 'where', 'over', \"haven't\", 'was', 'than', \"mustn't\", 'having', 'had', 've', 'by', 'yourselves', 'with', 'me', 'before', 'once', 'yours', \"it's\", 'because', 'we', 'more', 'both', \"that'll\", 'a', 'there', 'such', \"don't\", 'hasn', 'herself', 'if', 'these', \"you'll\", 'be', 'wouldn', 'after', 'no', 'needn', 'only', 'about', 'as', 'shouldn', \"wouldn't\", 't', 'very', \"hadn't\", 'it', 'while', 'most', 'weren', 'myself', 'all', 'or', 'now', 'shan', 'any', 'he', \"won't\", 'have', 'they', 'at', 'other', \"doesn't\", 'wasn', 'him', 'further', \"you've\", 'how', 'of', 'that', 'their', 'themselves', 'do', 'will', 'o', 'this', 'being', 'yourself', \"shouldn't\", \"you'd\", 'm', 'mustn', 'off', 'ours', 'an', 'again', 'you', 'theirs', 'doing', 'too', 'your', 'and', 'down', 'won', 'my', \"couldn't\", 'during', 'each', 'didn', \"hasn't\", 'did', 'so', 'above', \"isn't\", 'her', \"needn't\", 'i', 'been', \"shan't\", 'from', \"didn't\", 'don', 'out', 'when', 'own', 'himself', 'doesn', \"she's\", 'just', 'what', 'in', 'd', 'couldn', 'isn', 'hers', 'its', 'whom', 'here', 'until', 'below', 'who'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoTxObK9ZpSF",
        "outputId": "1adc9b6d-91b3-426a-9c14-3fe774c79588"
      },
      "source": [
        "tokens = [w for w in tokens if not w in stop_words]\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t58A5l9vZ_r2"
      },
      "source": [
        "# **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvUg9eybZ1yi",
        "outputId": "34eb1a01-9d5f-434d-cedd-d9f2669d50ad"
      },
      "source": [
        "porter = PorterStemmer()\n",
        "stems = []\n",
        "for t in tokens:    \n",
        "    stems.append(porter.stem(t))\n",
        "print(stems)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoJ2p9MnaZ5h"
      },
      "source": [
        "# **Lemmatizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BniSZznaTmU",
        "outputId": "209c33cb-aff4-4314-fa98-a0ff3aaf3937"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas=[]\n",
        "for t in tokens:\n",
        "  lemmas.append(lemmatizer.lemmatize(t))\n",
        "print (lemmas)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}